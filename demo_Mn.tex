\documentclass[12pt]{report}

% Paquetes comunes
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{amsthm}  % Carga el paquete necesario

\newtheorem{theorem}{Teorema}  % Define el entorno "theorem"
\geometry{a4paper, margin=2.5cm}

\begin{document}

% Índice
\tableofcontents
\newpage

\chapter{Preliminares}
\section{Metodo del segundo momento}
\section{Resultados sobre Galton-Watson Tree}
\section{Teorema de la Eleccion}

\chapter{Resultado sobre el branching process}
\section{Resultado sobre la ultima generación}
Durante esta sección, para no sobrecargar de notación, dado un arbol de Galton-Watson $T$ que no se extingue 
vamos a considerar $P(\cdot|T) = P(\cdot)$, analogamente con la esperanza.
\begin{theorem}
Dado un GFF $\eta = (\eta_{v})_{v \in T_{n}}$, construido como antes. Entonces,
\begin{align} 
E[\max_{v \in L_n} \eta_v] = n\sqrt{2\log m} \, (1 + o(1)).
\end{align}
\end{theorem}

\subsection{Cota superior}

Sea $\bar{Z}_n = \sum_{v \in L_n} \mathbf{1}_{S_v > (1 + \epsilon)x^* n}$, 
que cuenta la cantidad de vertices, en la $n$-th generación, 
se encuentran por arriba de $n x^*(1 + \epsilon)$. Aplicando el metodo del primer momento: 
tenemos, para todo $v \in L_n$,
\[
E\bar{Z}_n = |L_n| P(S_v > n(1 + \epsilon)x^*) \leq CW k^n e^{-n I((1 + \epsilon)x^*)},
\]
Donde aplicamos la desigualdad de Chebyshev en la ultima desigualdad y la definicion de $I$. Además, por 
la monotonia estricta de $I$, tenemos que $E \bar{Z}_n \leq e^{-n c(\epsilon)}$, 
para algun $c(\epsilon) > 0$. Por lo tanto,
\begin{align}
P(M_n > (1 + \epsilon) n x^*) \leq E [\bar{Z}_n] \leq CWe^{-c(\epsilon)n}.
\end{align}
Por otro lado,

\begin{align}
EM_n \leq EM_n\mathbf{1}_{M_n \geq 0} &= \int_{0}^{\infty} P(M_n > t) dt \nonumber\\
&= \int_{0}^{(1+\epsilon)nx^*} P(M_n > t) dt + \int_{(1+\epsilon)nx^*}^{\infty} P(M_n > t) dt .\nonumber
\end{align}
Luego, usando la cota de 4.2 en el segundo integrando de 4.3 e integrando, llegamos a que,
\begin{align}
EM_n \leq nx^*(1+\epsilon) + nx^* \frac{CWe^{-2nI(x^*)\epsilon}}{2nI(x^*)}.
\end{align}
Para todo $\epsilon > 0$. Haciendo $\epsilon \to 0$ obtenemos la cota superior.

\subsection{Cota inferior}
Sea $y>0$ independiente de $n$ y sea
\[
a_n = a_n(y) = x^*n - \frac{3}{2I'(x^*)} \text{log} n.
\]
Dado $v \in L_n$, definimos el evento
\[
A_v = \{ S_v \in [y+a_n-1,y+a_n], S_v(t)\leq a_n t / n + y, t = 1, \dots, n \},
\]
y sea
\[
Z_n = \sum_{v \in L_n}^{} \mathbf{1}_{A_v}.
\]

Para derivar una cota inferior de $EM_n$, primero necesitamos una cota inferior en la
cola derecha de la distribucion de $M_n$, la cual vamos a obtener utilizando el metodo del segundo momento. 
Para esto, primero calculamos $P(A_v)$. Recordemos que $I(x^*) = \text{log} k$, con $\lambda^*=I'(x^*)$. 
Introducimos un nuevo parametro $\lambda_{n}^{*}$ tal que
\[
\lambda_{n}^{*}\frac{a_n}{n}-\varLambda(\lambda_{n}^{*}) = I(a_n/n).
\]
Como $I'(a_n/n) = \lambda_{n}^{*}$, es facil chequear que $\lambda_{n}^{*} = 
\lambda^* - 3I''(x^*) \text{log}n/(2nI'(x^*)) + O(1/n)$. (En el caso Gaussiano, $\lambda_{n}^{*} = a_n / n $)

Definimos una nueva medida de probabilidad $Q$ en $\mathbb{R}$ por
\[
\frac{d\mu}{dQ}(x) = e^{-\lambda_{n}^{*}x + \varLambda(\lambda_{n}^{*})},
\]
y con un abuso de notacion continuamos usan $Q$ cuando hablemos sobre un paseo aleatorio 
cuyos incrementos sean i.i.d. y distribuidos de acuerdo a $Q$. Notar que en el caso Gaussiano, 
$Q$ solamente modifica la media de $P$. \\

Ahora podemos escribir 

\begin{align}
P(A_v) &= E_Q (e^{-\lambda_n^* S_v + n \Lambda(\lambda_n^*)} \mathbf{1}_{A_v}) \nonumber \\
&\geq e^{-n [\lambda_n^* a_n/n - \Lambda(\lambda_n^*)]} E_Q(A_v) \\
&= e^{-n I(a_n/n)} P_Q ( \tilde{S}_v \in [0,1], \tilde{S}_v (t) \geq 0, t = 1, \dots, n ). \nonumber 
\end{align}

donde $\tilde{S}_v (t) = a_n t / n - S_v (t)$ es un paseo aleatorio con incrementos i.i.d los cuales tienen media $0$ bajo $Q$. 
Ademas, en el caso Gaussiano, los incrementos son Gaussianos y no dependen de $n$.

Aplicando el Teorema de la Eleccion, obtenemos que 
\begin{align}
    P(A_v) \geq c_0 \frac{y+1}{n^{3/2}} e^{-nI((a_n+y)/n)}.
\end{align}
Agrego detalles sobre esto? \\
Como 
\[
I((a_n+y)/n) = I(x^*) - I'(x^*)\left(\frac{3}{2I'(x^*)}.\frac{\text{log}n}{n}-\frac{y}{n}\right)+O\left(\left(\frac{\text{log}n}{n}\right)^2\right),
\]
podemos concluir que
\[
P(A_v) \geq c_0 (y+1)k^{-n}e^{-I'(x^*)y},
\]
y por lo tanto
\begin{align}
    EZ_n = |L_n| P(A_v) \geq \frac{W_T}{C_T}c_0 (y+1) e^{-I'(x^*)y}.
\end{align}
Dejamos resaltada la dependencia de las constantes del arbol, ya que va a jugar un papel principal en porque pedimos que tenga grado acotado la distribucion.
\par
A continuacion necesitamos probar una cota soperior sobre
\begin{align}
    EZ_n^2 &= |L_n|P(A_v) + \sum_{v \neq w \in L_n}^{} P(A_v \cap A_w) 
           &= EZ_n + \sum_{v \in L_n}^{} \sum_{s = 1}^{n} |D_s^v| P(A_v \cap A_{v_s}),
\end{align}
Donde $D_s^v = \{ w \in L_n | d(v,w) = 2s \} $ y $v_s \in L_n$ tal que $d(v,v_s) = 2s$. \\
Necesito ver que $|D_s^v|$ es $O(k^s)$, es facil ver
\begin{align}
    |D_s^v| \leq |L_s(T_{v_s})| \leq C(T_{v_s}) K k^s.
\end{align}
Me faltaria acotar esta constante $C$ universalmente para todo $v_s \in L_{n-s}$. Para esto puedo hacer una 
especie de probabilidad total, donde condiciono a que todos estos subarboles a partir de la generacion $l$ 
ya esten a lo sumo a distancia $\beta$ de su W, elijo $l$ y $\beta$ de forma que este evento tenga alta 
probabilidad. Por lo que, puedo tomar $C = max\{k^l, \beta\}$. \\
Ahora veamo de acotar $P(A_v \cap A_{v_s})$, para esto condicionamos al valor de $S_v (n-s)$. 
En particular, con un poco de abuso de notacion, notamos $I_{j,s} = a_n (n-s)/n + [-j,-j+1] + y$, ahora tenemos que
\begin{align}
&P(A_u \cap A_{v_s}) \leq \sum_{j=1}^{\infty} P\Big(S_v(t) \leq a_n t/n + y,\, t = 1, \ldots, n - s,\, S_v(n - s) \in I_{j,s}\Big) \nonumber \\
&\times \max_{z \in I_{j,s}} \Big(P\big(S_v(s) \in [y + a_n - 1, y + a_n],
S_v(t) \leq a_n(n - s + t)/n + y,\, 1 \leq t \leq s \mid S_v(0) = z\big)\Big)^2. \nonumber
\end{align}
Agregar detalles \\
Usando la cota superior del Teorema de la Eleccion concluimos que
\begin{align}
    P(A_v \cap A_{v_s}) \leq \sum_{j=1}^{\infty} 
\frac{j^5 (y + 1)^2}{s^3 (n - s)^{3/2}} 
e^{-j \lambda^*} 
n^{3(n + s)/2n} 
k^{-(n + s)} 
e^{-(n + s) I'(x^*) y / n}.
\end{align}
Agregar detalles\\











\section{Resultado sobre todo el arbol}
Comparación con literatura o hipótesis.


\end{document}
